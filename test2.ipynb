{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"MisogynisticAttitudeDetection.csv/MisogynisticAttitudeDetection.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Comments</th>\n",
       "      <th>SubTask1</th>\n",
       "      <th>SubTask2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>674</td>\n",
       "      <td>Us society me aurat ko izzat kese mil sakti ha...</td>\n",
       "      <td>Pessimistic</td>\n",
       "      <td>Criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11747</td>\n",
       "      <td>Ye patna ko badnam krne ki kosis n kijiye poli...</td>\n",
       "      <td>Pessimistic</td>\n",
       "      <td>Criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2811</td>\n",
       "      <td>Dusro ki bahan ke sath wo vyawahar kabhi na kr...</td>\n",
       "      <td>Optimistic</td>\n",
       "      <td>Suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>587</td>\n",
       "      <td>Ye sab ke sakkar main mat aao. Ladkiyo ne haza...</td>\n",
       "      <td>Optimistic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6473</td>\n",
       "      <td>Yehi hai apna sachai ladai hai ✒</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifier                                           Comments     SubTask1  \\\n",
       "0         674  Us society me aurat ko izzat kese mil sakti ha...  Pessimistic   \n",
       "1       11747  Ye patna ko badnam krne ki kosis n kijiye poli...  Pessimistic   \n",
       "2        2811  Dusro ki bahan ke sath wo vyawahar kabhi na kr...   Optimistic   \n",
       "3         587  Ye sab ke sakkar main mat aao. Ladkiyo ne haza...   Optimistic   \n",
       "4        6473                   Yehi hai apna sachai ladai hai ✒      Neutral   \n",
       "\n",
       "     SubTask2  \n",
       "0   Criticism  \n",
       "1   Criticism  \n",
       "2  Suggestion  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming dataset has 'comment' and 'label' columns\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Comments', 'SubTask1', 'SubTask2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>SubTask1</th>\n",
       "      <th>SubTask2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Us society me aurat ko izzat kese mil sakti ha...</td>\n",
       "      <td>Pessimistic</td>\n",
       "      <td>Criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ye patna ko badnam krne ki kosis n kijiye poli...</td>\n",
       "      <td>Pessimistic</td>\n",
       "      <td>Criticism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dusro ki bahan ke sath wo vyawahar kabhi na kr...</td>\n",
       "      <td>Optimistic</td>\n",
       "      <td>Suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes Bhai hun Youth hi Youth ko sudhar sakte ha...</td>\n",
       "      <td>Optimistic</td>\n",
       "      <td>Suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oh beti , ladkiya bhi r@pe karti hai kisne kah...</td>\n",
       "      <td>Pessimistic</td>\n",
       "      <td>Criticism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments     SubTask1    SubTask2\n",
       "0  Us society me aurat ko izzat kese mil sakti ha...  Pessimistic   Criticism\n",
       "1  Ye patna ko badnam krne ki kosis n kijiye poli...  Pessimistic   Criticism\n",
       "2  Dusro ki bahan ke sath wo vyawahar kabhi na kr...   Optimistic  Suggestion\n",
       "5  Yes Bhai hun Youth hi Youth ko sudhar sakte ha...   Optimistic  Suggestion\n",
       "8  Oh beti , ladkiya bhi r@pe karti hai kisne kah...  Pessimistic   Criticism"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna(subset=['SubTask1'])\n",
    "df=df.dropna(subset=['SubTask2'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>SubTask1</th>\n",
       "      <th>SubTask2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Us society me aurat ko izzat kese mil sakti ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ye patna ko badnam krne ki kosis n kijiye poli...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dusro ki bahan ke sath wo vyawahar kabhi na kr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes Bhai hun Youth hi Youth ko sudhar sakte ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oh beti , ladkiya bhi r@pe karti hai kisne kah...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments  SubTask1  SubTask2\n",
       "0  Us society me aurat ko izzat kese mil sakti ha...         1         2\n",
       "1  Ye patna ko badnam krne ki kosis n kijiye poli...         1         2\n",
       "2  Dusro ki bahan ke sath wo vyawahar kabhi na kr...         0         1\n",
       "5  Yes Bhai hun Youth hi Youth ko sudhar sakte ha...         0         1\n",
       "8  Oh beti , ladkiya bhi r@pe karti hai kisne kah...         1         2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attitude_mapping = {\"Optimistic\": 0, \"Pessimistic\": 1, \"Neutral\": 2}\n",
    "category_mapping = {\"Appreciation\": 0, \"Suggestion\": 1, \"Criticism\": 2, \"Offensive\": 3, \"None\": 4}\n",
    "df['SubTask1'] = df['SubTask1'].map(attitude_mapping)\n",
    "df['SubTask2'] = df['SubTask2'].map(category_mapping)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhakt\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text preprocessing function\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove punctuation & numbers\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['cleaned_comment'] = df['Comments'].apply(clean_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for SubTask1 (Optimistic, Pessimistic, Neutral)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_comment'], df['SubTask1'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into numerical vectors (TF-IDF)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results (SubTask1 - Attitude Detection):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.15      0.24       201\n",
      "           1       0.82      0.98      0.89       794\n",
      "\n",
      "    accuracy                           0.81       995\n",
      "   macro avg       0.75      0.57      0.57       995\n",
      "weighted avg       0.79      0.81      0.76       995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression Model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Logistic Regression Results (SubTask1 - Attitude Detection):\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results (SubTask1 - Attitude Detection):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.32      0.44       201\n",
      "           1       0.85      0.96      0.90       794\n",
      "\n",
      "    accuracy                           0.83       995\n",
      "   macro avg       0.77      0.64      0.67       995\n",
      "weighted avg       0.82      0.83      0.81       995\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM Model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"SVM Results (SubTask1 - Attitude Detection):\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': tensor([[  101,  1038, 10932,  ...,     0,     0,     0],\n",
      "        [  101,  5292,  1046,  ...,     0,     0,     0],\n",
      "        [  101,  6768, 24547,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  5003,  2213,  ...,  2039,  2121,   102],\n",
      "        [  101,  5378,  4424,  ...,     0,     0,     0],\n",
      "        [  101,  8670,  4017,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}, tensor([1, 1, 1, 0, 1, 1, 1, 0])]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Convert dataset into tokenized format\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts  # Store text comments\n",
    "        self.labels = labels  # Store labels (0,1,2 for classification)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)  # Return total dataset size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoded_text = tokenizer(\n",
    "            str(self.texts[idx]),  # Ensure text is a string\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {key: val.squeeze() for key, val in encoded_text.items()}, torch.tensor(self.labels[idx])\n",
    "\n",
    "# ✅ Ensure `X_train` and `y_train` are in the correct format\n",
    "if isinstance(X_train, pd.Series):  \n",
    "    X_train = X_train.astype(str).tolist()  # Convert Series to list of strings\n",
    "elif isinstance(X_train, list):  \n",
    "    X_train = [str(text) for text in X_train]  # Ensure all values are strings\n",
    "\n",
    "if isinstance(y_train, pd.Series):  \n",
    "    y_train = y_train.tolist()  # Convert Series to list\n",
    "\n",
    "# ✅ Remove any NaN values (if present)\n",
    "X_train = [text if text else \" \" for text in X_train]  # Replace NaN with empty string\n",
    "\n",
    "# Prepare dataset\n",
    "train_dataset = CommentDataset(X_train, y_train)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Print a sample batch (For Debugging)\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "model.train()  # Set model to training mode\n",
    "\n",
    "# Define optimizer & loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)  # Learning rate = 5e-5\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load BERT with a classification head\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/498 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m optimizer.zero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Move batch to device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m input_ids = \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.to(device)\n\u001b[32m     16\u001b[39m attention_mask = batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n\u001b[32m     17\u001b[39m labels = batch[\u001b[32m1\u001b[39m].to(device)  \u001b[38;5;66;03m# Labels\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "epochs = 3  # Number of training epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    loop = tqdm(train_dataloader, leave=True)\n",
    "    \n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        # Move batch to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[1].to(device)  # Labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
